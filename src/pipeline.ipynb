{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.data_preprocessor import FinancialDataPreprocessor\n",
    "\n",
    "preprocessor = FinancialDataPreprocessor()\n",
    "\n",
    "preprocessor.load_data(\n",
    "    bitcoin_path=r\"C:\\Users\\enesm\\OneDrive\\Masaüstü\\tubitak\\data\\Bitcoin Historical Data.csv\",\n",
    "    usd_path=r\"C:\\Users\\enesm\\OneDrive\\Masaüstü\\tubitak\\data\\dolar.csv\",\n",
    "    gold_path=r\"C:\\Users\\enesm\\OneDrive\\Masaüstü\\tubitak\\data\\XAU_USD Geçmiş Verileri.csv\",\n",
    ")\n",
    "\n",
    "merged_df = preprocessor.merge_data()\n",
    "\n",
    "merged_df.to_csv(\n",
    "    r\"C:\\Users\\enesm\\OneDrive\\Masaüstü\\tubitak\\data\\merged_data.csv\", index=False\n",
    ")\n",
    "\n",
    "data_info = preprocessor.get_data_info()s\n",
    "print(\"Data Shape:\", data_info[\"shape\"])\n",
    "print(\"Date Range:\", data_info[\"date_range\"])\n",
    "print(\"Unique Dates:\", data_info[\"unique_dates\"])\n",
    "print(\"Missing Values:\", data_info[\"missing_values\"])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corr matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_matrix = merged_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.data_eda import FinancialDataEDA\n",
    "\n",
    "eda = FinancialDataEDA(merged_df)\n",
    "\n",
    "time_series = eda.plot_time_series()\n",
    "time_series.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = eda.plot_correlation_matrix()\n",
    "correlation_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns = eda.plot_returns_distribution()\n",
    "# returns.show()\n",
    "\n",
    "detailed_corr = eda.get_detailed_correlations()\n",
    "print(\"\\nTop 10 Strongest Correlations:\")\n",
    "print(detailed_corr.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk metrics\n",
    "# risk_metrics = eda.generate_risk_metrics()\n",
    "# for asset, metrics in risk_metrics.items():\n",
    "#    print(f\"\\n{asset} Metrics:\")\n",
    "#    for metric, value in metrics.items():\n",
    "#        print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.model_preprocessor import FinancialDataPreprocessor\n",
    "\n",
    "\n",
    "preprocessor = FinancialDataPreprocessor(lookback_period=30)\n",
    "\n",
    "processed_data = preprocessor.prepare_data(\n",
    "    df=merged_df,\n",
    "    train_start=\"2023-09-01\",\n",
    "    train_end=\"2024-09-14\",\n",
    "    test_start=\"2024-09-15\",\n",
    "    test_end=\"2024-09-30\",\n",
    ")\n",
    "\n",
    "train_data = processed_data[\"train\"]\n",
    "test_data = processed_data[\"test\"]\n",
    "\n",
    "preprocessor.check_data_quality(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_features = ['Date', 'Price','Open', 'High', 'Low', 'Vol.', 'Change %', 'usd_buy',\n",
    "#'usd_sell', 'gold_Price', 'gold_Open', 'gold_High', 'gold_Low',\n",
    "#'gold_Change', 'RSI', 'MA_7', 'EMA_7', 'MA_14',\n",
    "#'EMA_14','Volume_MA','BTC_Gold_Ratio','BTC_USD_Ratio']\n",
    "\n",
    "#'usd_sell', 'MA_14',\n",
    "\n",
    "selected_features = ['Date', 'Price', 'High', 'usd_buy',\n",
    "        'gold_Price', 'RSI', 'MA_7', 'BTC_Gold_Ratio','BTC_USD_Ratio']\n",
    "\n",
    "train_data = train_data[selected_features]\n",
    "test_data = test_data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Örnek olarak merged_df'yi oluşturduğunuzu varsayalım\n",
    "# merged_df = pd.read_csv('your_data.csv')  # Eğer bir dosyadan yükleyecekseniz\n",
    "\n",
    "# Korelasyon matrisini hesaplayın\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "# Heatmap'i çizdirin\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation After Feature Engineering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.colheader_justify\", \"center\")\n",
    "\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "mask = np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    "high_corr_matrix = correlation_matrix.where(mask)\n",
    "\n",
    "high_corr = (\n",
    "    high_corr_matrix.stack()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: \"Correlation\"})\n",
    ")\n",
    "\n",
    "\n",
    "threshold = 0.8\n",
    "high_corr_filtered = high_corr[high_corr[\"Correlation\"].abs() >= threshold]\n",
    "\n",
    "high_corr_filtered[[\"Feature 1\", \"Feature 2\"]] = np.sort(\n",
    "    high_corr_filtered[[\"Feature 1\", \"Feature 2\"]], axis=1\n",
    ")\n",
    "high_corr_filtered = high_corr_filtered.drop_duplicates(\n",
    "    subset=[\"Feature 1\", \"Feature 2\"]\n",
    ")\n",
    "\n",
    "high_corr_filtered = high_corr_filtered.sort_values(\n",
    "    by=\"Correlation\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "high_corr_filtered.index += 1\n",
    "high_corr_filtered.index.name = \"Index\"\n",
    "\n",
    "print(high_corr_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import FinancialModelPipeline\n",
    "\n",
    "pipeline = FinancialModelPipeline(train_data, test_data)\n",
    "pipeline.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.model_visualizations import ModelVisualizer\n",
    "\n",
    "visualizer = ModelVisualizer(pipeline)\n",
    "\n",
    "# model metrics\n",
    "fig_metrics = visualizer.plot_model_metrics()\n",
    "fig_metrics.show()\n",
    "\n",
    "# best model\n",
    "fig_best = visualizer.plot_best_model_predictions()\n",
    "fig_best.show()\n",
    "\n",
    "# all predictions\n",
    "fig_all = visualizer.plot_all_predictions()\n",
    "fig_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision_Tree, Random_Forest, XGBoost, LightGBM, CatBoost, AdaBoost\n",
    "fig_importance = visualizer.plot_feature_importance(\"LightGBM\")\n",
    "if fig_importance:\n",
    "    fig_importance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parametre Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune selected models\n",
    "# pipeline.tune_models(['Random_Forest', 'XGBoost'])\n",
    "\n",
    "# tune all models\n",
    "# pipeline.tune_models()\n",
    "\n",
    "# tuning results\n",
    "# pipeline.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from model.lstm_model import FinancialLSTM\n",
    "from preprocessing.lstm_model_preprocessor import LSTMDataPreprocessor\n",
    "from preprocessing.model_preprocessor import FinancialDataPreprocessor\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\enesm\\OneDrive\\Masaüstü\\tubitak\\data\\merged_data.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "\n",
    "sequence_length = 20\n",
    "\n",
    "data_preprocessor = FinancialDataPreprocessor(lookback_period=30)\n",
    "lstm_preprocessor = LSTMDataPreprocessor(\n",
    "    sequence_length=sequence_length,\n",
    "    target_column=\"Price\",\n",
    "    feature_columns=[\n",
    "        \"Price\",\n",
    "        \"High\",\n",
    "        \"Low\",\n",
    "        \"Vol.\",\n",
    "        \"MA_7\",\n",
    "        \"RSI\",\n",
    "        \"MACD\",\n",
    "        \"BB_middle\",\n",
    "        \"Price_Momentum_1\",\n",
    "        \"Price_Momentum_3\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "preprocessed_data = data_preprocessor.prepare_data(\n",
    "    df=df,\n",
    "    train_start=\"2022-01-01\",\n",
    "    train_end=\"2024-08-15\",  \n",
    "    test_start=\"2024-08-16\",\n",
    "    test_end=\"2024-09-30\",\n",
    ")\n",
    "\n",
    "lstm_data = lstm_preprocessor.prepare_lstm_data(preprocessed_data)\n",
    "\n",
    "model = FinancialLSTM(\n",
    "    sequence_length=sequence_length,\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    lstm_units=[128, 64, 32],\n",
    "    dropout_rate=0.1,\n",
    ")\n",
    "\n",
    "metrics = model.train(lstm_data)\n",
    "print(\"\\nTraining metrics:\", metrics)\n",
    "\n",
    "predictions = model.predict(lstm_data[\"test\"][\"X\"])\n",
    "predictions = lstm_preprocessor.inverse_transform_predictions(predictions)\n",
    "\n",
    "test_dates = preprocessed_data[\"test\"][\"Date\"].values[\n",
    "    sequence_length : len(predictions) + sequence_length\n",
    "]\n",
    "y_true = preprocessed_data[\"test\"][lstm_preprocessor.target_column].values[\n",
    "    sequence_length : len(predictions) + sequence_length\n",
    "]\n",
    "\n",
    "model.plot_predictions(test_dates, y_true, predictions.flatten())\n",
    "\n",
    "eval_metrics = model.evaluate_predictions(y_true, predictions.flatten())\n",
    "print(\"\\nTest Set Performance Metrics:\")\n",
    "print(f\"MAE: ${eval_metrics['mae']:,.2f}\")\n",
    "print(f\"RMSE: ${eval_metrics['rmse']:,.2f}\")\n",
    "print(f\"R2 Score: {eval_metrics['r2']:.4f}\")\n",
    "print(f\"MAPE: {eval_metrics['mape']:.2f}%\")\n",
    "\n",
    "\n",
    "performance_log = {\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"metrics\": eval_metrics,\n",
    "    \"model_params\": {\n",
    "        \"sequence_length\": sequence_length,\n",
    "        \"lstm_units\": [128, 64, 32],\n",
    "        \"dropout_rate\": 0.1,\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 150,\n",
    "    },\n",
    "    \"train_period\": f\"{preprocessed_data['train']['Date'].iloc[0]} to {preprocessed_data['train']['Date'].iloc[-1]}\",\n",
    "    \"test_period\": f\"{preprocessed_data['test']['Date'].iloc[0]} to {preprocessed_data['test']['Date'].iloc[-1]}\",\n",
    "}\n",
    "\n",
    "with open(\"model\\lstm_performance_log.json\", \"w\") as f:\n",
    "    json.dump(performance_log, f, indent=4)\n",
    "\n",
    "print(\"\\nModel performance saved to 'model_performance_log.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.automl_autogluon import BitcoinPricePredictor\n",
    "\n",
    "PARAMS = {\n",
    "    'data_path': r'C:\\Users\\enesm\\OneDrive\\Masaüstü\\tubitak\\data\\merged_data.csv',  \n",
    "    'train_start':\"2022-01-01\",\n",
    "    'train_end':\"2024-09-14\",\n",
    "    'test_start':\"2024-09-15\",\n",
    "    'test_end':\"2024-09-30\",\n",
    "    'time_limit': 600  \n",
    "}\n",
    "\n",
    "predictor = BitcoinPricePredictor()\n",
    "\n",
    "print(\"Veri hazırlanıyor...\")\n",
    "train_data, test_data = predictor.prepare_data(\n",
    "    PARAMS['data_path'],\n",
    "    PARAMS['train_start'],\n",
    "    PARAMS['train_end'],\n",
    "    PARAMS['test_start'],\n",
    "    PARAMS['test_end']\n",
    ")\n",
    "\n",
    "print(\"\\nModel eğitimi başlıyor...\")\n",
    "predictor.train_model(time_limit=PARAMS['time_limit'])\n",
    "\n",
    "print(\"\\nModel değerlendiriliyor...\")\n",
    "results = predictor.evaluate_model()\n",
    "\n",
    "print(\"\\nModel Performans Metrikleri:\")\n",
    "print(\"-\" * 30)\n",
    "for metric, value in results['metrics'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "importance_df = results['feature_importance']\n",
    "if isinstance(importance_df, pd.DataFrame):\n",
    "    importance_series = importance_df.iloc[:, 0]\n",
    "else:\n",
    "    importance_series = importance_df\n",
    "\n",
    "importance_series = importance_series.sort_values(ascending=True)\n",
    "top_10_features = importance_series.tail(10)\n",
    "\n",
    "y_pos = np.arange(len(top_10_features))\n",
    "plt.barh(y_pos, top_10_features.values)\n",
    "plt.yticks(y_pos, top_10_features.index)\n",
    "plt.title('En Önemli 10 Feature')\n",
    "plt.xlabel('Önem Skoru')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "predictions_df = results['predictions']\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(test_data['Date'].values, predictions_df['actual'], label='Gerçek Değer', alpha=0.7)\n",
    "plt.plot(test_data['Date'].values, predictions_df['predicted'], label='Tahmin', alpha=0.7)\n",
    "plt.title('Bitcoin Fiyat Tahminleri vs Gerçek Değerler')\n",
    "plt.xlabel('Tarih')\n",
    "plt.ylabel('Fiyat')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "errors = predictions_df['actual'] - predictions_df['predicted']\n",
    "sns.histplot(errors, kde=True)\n",
    "plt.title('Tahmin Hatalarının Dağılımı')\n",
    "plt.xlabel('Hata')\n",
    "plt.ylabel('Frekans')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_data['Date'],\n",
    "    'Actual': predictions_df['actual'],\n",
    "    'Predicted': predictions_df['predicted'],\n",
    "    'Error': errors\n",
    "})\n",
    "\n",
    "results_path = r'C:\\Users\\enesm\\OneDrive\\Masaüstü\\tubitak\\src\\model\\autogluon_predictions.csv'\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"\\nTahminler '{results_path}' dosyasına kaydedildi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
