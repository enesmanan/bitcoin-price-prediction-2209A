{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.data_preprocessor import FinancialDataPreprocessor\n",
    "\n",
    "preprocessor = FinancialDataPreprocessor()\n",
    "\n",
    "# change the data paths to the correct ones\n",
    "preprocessor.load_data(\n",
    "    bitcoin_path=r\"data\\Bitcoin Historical Data.csv\",\n",
    "    usd_path=r\"data\\dolar.csv\",\n",
    "    gold_path=r\"data\\XAU_USD Geçmiş Verileri.csv\",\n",
    ")\n",
    "\n",
    "merged_df = preprocessor.merge_data()\n",
    "\n",
    "merged_df.to_csv(\n",
    "    r\"data\\merged_data.csv\", index=False\n",
    ")\n",
    "\n",
    "data_info = preprocessor.get_data_info()\n",
    "print(\"Data Shape:\", data_info[\"shape\"])\n",
    "print(\"Date Range:\", data_info[\"date_range\"])\n",
    "print(\"Unique Dates:\", data_info[\"unique_dates\"])\n",
    "print(\"Missing Values:\", data_info[\"missing_values\"])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corr matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_matrix = merged_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.data_eda import FinancialDataEDA\n",
    "\n",
    "eda = FinancialDataEDA(merged_df)\n",
    "\n",
    "time_series = eda.plot_time_series()\n",
    "time_series.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = eda.plot_correlation_matrix()\n",
    "correlation_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns = eda.plot_returns_distribution()\n",
    "# returns.show()\n",
    "\n",
    "detailed_corr = eda.get_detailed_correlations()\n",
    "print(\"\\nTop 10 Strongest Correlations:\")\n",
    "print(detailed_corr.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk metrics\n",
    "# risk_metrics = eda.generate_risk_metrics()\n",
    "# for asset, metrics in risk_metrics.items():\n",
    "#    print(f\"\\n{asset} Metrics:\")\n",
    "#    for metric, value in metrics.items():\n",
    "#        print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.model_preprocessor import FinancialDataPreprocessor\n",
    "\n",
    "\n",
    "preprocessor = FinancialDataPreprocessor(lookback_period=15)\n",
    "\n",
    "processed_data = preprocessor.prepare_data(\n",
    "    df=merged_df,\n",
    "    train_start=\"2023-09-01\",\n",
    "    train_end=\"2024-09-14\",\n",
    "    test_start=\"2024-09-15\",\n",
    "    test_end=\"2024-09-30\",\n",
    ")\n",
    "\n",
    "train_data = processed_data[\"train\"]\n",
    "test_data = processed_data[\"test\"]\n",
    "\n",
    "preprocessor.check_data_quality(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_features = ['Date', 'Price','Open', 'High', 'Low', 'Vol.', 'Change %', 'usd_buy',\n",
    "#'usd_sell', 'gold_Price', 'gold_Open', 'gold_High', 'gold_Low',\n",
    "#'gold_Change', 'RSI', 'MA_7', 'EMA_7', 'MA_14',\n",
    "#'EMA_14','Volume_MA','BTC_Gold_Ratio','BTC_USD_Ratio']\n",
    "\n",
    "#'usd_sell', 'MA_14',\n",
    "\n",
    "selected_features = ['Date', 'Price', 'High', 'usd_buy',\n",
    "        'gold_Price', 'RSI', 'MA_7', 'BTC_Gold_Ratio','BTC_USD_Ratio']\n",
    "\n",
    "train_data = train_data[selected_features]\n",
    "test_data = test_data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import FinancialModelPipeline\n",
    "\n",
    "pipeline = FinancialModelPipeline(train_data, test_data)\n",
    "pipeline.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.model_visualizations import ModelVisualizer\n",
    "\n",
    "visualizer = ModelVisualizer(pipeline)\n",
    "\n",
    "# model metrics\n",
    "fig_metrics = visualizer.plot_model_metrics()\n",
    "fig_metrics.show()\n",
    "\n",
    "# best model\n",
    "fig_best = visualizer.plot_best_model_predictions()\n",
    "fig_best.show()\n",
    "\n",
    "# all predictions\n",
    "fig_all = visualizer.plot_all_predictions()\n",
    "fig_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision_Tree, Random_Forest, XGBoost, LightGBM, CatBoost, AdaBoost\n",
    "fig_importance = visualizer.plot_feature_importance(\"LightGBM\")\n",
    "if fig_importance:\n",
    "    fig_importance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parametre Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune selected models\n",
    "# pipeline.tune_models(['Random_Forest', 'XGBoost'])\n",
    "\n",
    "# tune all models\n",
    "# pipeline.tune_models()\n",
    "\n",
    "# tuning results\n",
    "# pipeline.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model.lstm_model import FinancialLSTM\n",
    "from preprocessing.lstm_model_preprocessor import LSTMDataPreprocessor\n",
    "from preprocessing.model_preprocessor import FinancialDataPreprocessor\n",
    "\n",
    "df = pd.read_csv(r\"data\\merged_data.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "sequence_length = 10\n",
    "\n",
    "data_preprocessor = FinancialDataPreprocessor(lookback_period=15)\n",
    "lstm_preprocessor = LSTMDataPreprocessor(\n",
    "    sequence_length=sequence_length,\n",
    "    target_column=\"Price\",\n",
    "    feature_columns=[\n",
    "        \"High\",\n",
    "        \"Low\",\n",
    "        \"Vol.\",\n",
    "        \"MA_7\",\n",
    "        \"RSI\",\n",
    "        \"MACD\",\n",
    "        \"BB_middle\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "preprocessed_data = data_preprocessor.prepare_data(\n",
    "    df=df,\n",
    "    train_start=\"2023-01-01\",\n",
    "    train_end=\"2024-09-14\",  \n",
    "    test_start=\"2024-09-15\",\n",
    "    test_end=\"2024-09-30\",\n",
    ")\n",
    "\n",
    "lstm_data = lstm_preprocessor.prepare_lstm_data(preprocessed_data)\n",
    "\n",
    "model = FinancialLSTM(\n",
    "    sequence_length=sequence_length,\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    lstm_units=[128, 64, 32],\n",
    "    dropout_rate=0.1,\n",
    ")\n",
    "\n",
    "metrics = model.train(lstm_data)\n",
    "print(\"\\nTrain metrics:\", metrics)\n",
    "\n",
    "# sliding window\n",
    "combined_data = pd.concat([\n",
    "    preprocessed_data[\"train\"].iloc[-sequence_length:],\n",
    "    preprocessed_data[\"test\"]\n",
    "])\n",
    "\n",
    "all_test_dates = preprocessed_data[\"test\"][\"Date\"].values\n",
    "all_test_prices = preprocessed_data[\"test\"][lstm_preprocessor.target_column].values\n",
    "all_test_predictions = np.zeros(len(all_test_dates))\n",
    "\n",
    "# Sliding window prediction\n",
    "for i in range(len(all_test_dates)):\n",
    "    if i + sequence_length <= len(combined_data):\n",
    "        window = combined_data.iloc[i:i+sequence_length]\n",
    "        \n",
    "        features = window[lstm_preprocessor.feature_columns].values\n",
    "        \n",
    "        scaled_features = lstm_preprocessor.feature_scaler.transform(features)\n",
    "        \n",
    "        scaled_pred = model.predict(np.array([scaled_features]))\n",
    "        \n",
    "        pred = lstm_preprocessor.inverse_transform_predictions(scaled_pred)\n",
    "        \n",
    "        all_test_predictions[i] = pred[0][0]\n",
    "\n",
    "# scaled rmse\n",
    "valid_indices = all_test_predictions != 0\n",
    "y_true_scaled = lstm_preprocessor.target_scaler.transform(all_test_prices[valid_indices].reshape(-1, 1))\n",
    "y_pred_scaled = lstm_preprocessor.target_scaler.transform(all_test_predictions[valid_indices].reshape(-1, 1))\n",
    "scaled_rmse = np.sqrt(mean_squared_error(y_true_scaled, y_pred_scaled))\n",
    "print(f\"\\nScaled RMSE: {scaled_rmse:.4f}\")\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=all_test_dates, \n",
    "        y=all_test_prices, \n",
    "        name=\"Actual Price\", \n",
    "        line=dict(color=\"blue\", width=2)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=all_test_dates[valid_indices],\n",
    "        y=all_test_predictions[valid_indices],\n",
    "        name=\"Predicton\",\n",
    "        line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "error = np.abs(all_test_prices[valid_indices] - all_test_predictions[valid_indices])\n",
    "error_band = np.std(error) * 2\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=all_test_dates[valid_indices],\n",
    "        y=all_test_predictions[valid_indices] + error_band,\n",
    "        fill=None,\n",
    "        mode=\"lines\",\n",
    "        line_color=\"rgba(255,0,0,0)\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=all_test_dates[valid_indices],\n",
    "        y=all_test_predictions[valid_indices] - error_band,\n",
    "        fill=\"tonexty\",\n",
    "        mode=\"lines\",\n",
    "        line_color=\"rgba(255,0,0,0)\",\n",
    "        fillcolor=\"rgba(255,0,0,0.2)\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Bitcoin Price - Actual vs Predicton (All 15 Days Test Period)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Price (USD)\",\n",
    "    hovermode=\"x unified\",\n",
    "    showlegend=True,\n",
    "    template=\"plotly_white\",\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    xaxis=dict(\n",
    "        tickformat=\"%Y-%m-%d\",\n",
    "        tickangle=45,\n",
    "    ),\n",
    "    yaxis=dict(tickformat=\"$,.0f\"),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "eval_metrics = model.evaluate_predictions(\n",
    "    all_test_prices[valid_indices], \n",
    "    all_test_predictions[valid_indices]\n",
    ")\n",
    "\n",
    "print(f\"MAE: {eval_metrics['mae']:,.2f}\")\n",
    "print(f\"RMSE: {eval_metrics['rmse']:,.2f}\")\n",
    "print(f\"R2 Skor: {eval_metrics['r2']:.4f}\")\n",
    "print(f\"MAPE: {eval_metrics['mape']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.automl_autogluon import BitcoinPricePredictor\n",
    "from preprocessing.model_preprocessor import FinancialDataPreprocessor\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "\n",
    "data_preprocessor = FinancialDataPreprocessor(lookback_period=30)\n",
    "preprocessed_data = data_preprocessor.prepare_data(\n",
    "    df=df,\n",
    "    train_start=\"2023-01-01\",\n",
    "    train_end=\"2024-09-30\",\n",
    "    test_start=\"2024-10-01\",\n",
    "    test_end=\"2024-10-30\",\n",
    ")\n",
    "\n",
    "selected_features = [\n",
    "    \"High\",\n",
    "    \"usd_buy\",\n",
    "    \"gold_Price\",\n",
    "    \"RSI\",\n",
    "    \"MA_7\",\n",
    "    \"BTC_Gold_Ratio\",\n",
    "    \"BTC_USD_Ratio\",\n",
    "]\n",
    "\n",
    "train_data = preprocessed_data[\"train\"].copy()\n",
    "test_data = preprocessed_data[\"test\"].copy()\n",
    "\n",
    "train_features = train_data[selected_features + [\"Date\", \"Price\"]].copy()\n",
    "test_features = test_data[selected_features + [\"Date\", \"Price\"]].copy()\n",
    "\n",
    "print(\"Train kolonları:\", train_features.columns.tolist())\n",
    "print(\"Test kolonları:\", test_features.columns.tolist())\n",
    "print(\n",
    "    \"Tekrarlanan kolonlar:\",\n",
    "    train_features.columns[train_features.columns.duplicated()].tolist(),\n",
    ")\n",
    "\n",
    "try:\n",
    "    predictor = BitcoinPricePredictor(\n",
    "        target_column=\"Price\",\n",
    "        feature_columns=selected_features,\n",
    "        time_limit=600,  # 10 dakika\n",
    "    )\n",
    "\n",
    "    print(\"\\nModel eğitimi başlıyor...\")\n",
    "    predictor.train_model(train_features)\n",
    "\n",
    "    print(\"\\nModel değerlendiriliyor...\")\n",
    "    results = predictor.evaluate_model(test_features)\n",
    "\n",
    "    print(\"\\nModel Performans Metrikleri:\")\n",
    "    print(\"-\" * 30)\n",
    "    for metric, value in results[\"metrics\"].items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    importance_df = results[\"feature_importance\"]\n",
    "    if isinstance(importance_df, pd.DataFrame):\n",
    "        importance_series = importance_df.iloc[:, 0]\n",
    "    else:\n",
    "        importance_series = importance_df\n",
    "\n",
    "    importance_series = importance_series.sort_values(ascending=True)\n",
    "    plt.barh(range(len(importance_series)), importance_series.values)\n",
    "    plt.yticks(range(len(importance_series)), importance_series.index)\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.xlabel(\"Importance Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    predictions_df = results[\"predictions\"]\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(\n",
    "        test_features[\"Date\"], predictions_df[\"actual\"], label=\"Gerçek Değer\", alpha=0.7\n",
    "    )\n",
    "    plt.plot(\n",
    "        test_features[\"Date\"], predictions_df[\"predicted\"], label=\"Tahmin\", alpha=0.7\n",
    "    )\n",
    "    plt.title(\"Bitcoin Fiyat Tahminleri vs Gerçek Değerler\")\n",
    "    plt.xlabel(\"Tarih\")\n",
    "    plt.ylabel(\"Fiyat\")\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    errors = predictions_df[\"actual\"] - predictions_df[\"predicted\"]\n",
    "    sns.histplot(errors, kde=True)\n",
    "    plt.title(\"Tahmin Hatalarının Dağılımı\")\n",
    "    plt.xlabel(\"Hata\")\n",
    "    plt.ylabel(\"Frekans\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    performance_log = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"metrics\": results[\"metrics\"],\n",
    "        \"model_params\": {\n",
    "            \"time_limit\": 600,\n",
    "            \"target_column\": \"Price\",\n",
    "            \"feature_columns\": selected_features,\n",
    "        },\n",
    "        \"train_period\": f\"{train_features['Date'].iloc[0]} to {train_features['Date'].iloc[-1]}\",\n",
    "        \"test_period\": f\"{test_features['Date'].iloc[0]} to {test_features['Date'].iloc[-1]}\",\n",
    "    }\n",
    "\n",
    "    with open(\"model/autogluon_performance_log.json\", \"w\") as f:\n",
    "        json.dump(performance_log, f, indent=4)\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Date\": test_features[\"Date\"],\n",
    "            \"Actual\": predictions_df[\"actual\"],\n",
    "            \"Predicted\": predictions_df[\"predicted\"],\n",
    "            \"Error\": errors,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    results_path = \"model/autogluon_predictions.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    print(f\"\\nTahminler '{results_path}' dosyasına kaydedildi.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Hata oluştu: {str(e)}\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
